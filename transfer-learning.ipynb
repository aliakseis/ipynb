{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu_2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu_2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu_2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu_2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu_2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu_2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications import MobileNetV2, ResNet50, InceptionV3, Xception # try to use them and see which is better\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.utils import get_file\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# 5 types of flowers\n",
    "num_classes = 6\n",
    "# training epochs\n",
    "epochs = 20\n",
    "# size of each image\n",
    "IMAGE_SHAPE = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"This function downloads, extracts, loads, normalizes and one-hot encodes Flower Photos dataset\"\"\"\n",
    "    # download the dataset and extract it\n",
    "    #data_dir = get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    #                                     fname='flower_photos', untar=True)\n",
    "    \n",
    "    data_dir = \"/dataset/dataset-resized\"\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "       \n",
    "    # count how many images are there\n",
    "    image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "    print(\"Number of images:\", image_count)\n",
    "    # get all classes for this dataset (types of flowers) excluding LICENSE file\n",
    "    CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \".DS_Store\"])\n",
    "    # roses = list(data_dir.glob('roses/*'))\n",
    "    # 20% validation set 80% training set\n",
    "    image_generator = ImageDataGenerator(rescale=1/255, validation_split=0.2)\n",
    "    # make the training dataset generator\n",
    "    train_data_gen = image_generator.flow_from_directory(directory=str(data_dir), batch_size=batch_size,\n",
    "                                                        classes=list(CLASS_NAMES), target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "                                                        shuffle=True, subset=\"training\")\n",
    "    # make the validation dataset generator\n",
    "    test_data_gen = image_generator.flow_from_directory(directory=str(data_dir), batch_size=batch_size, \n",
    "                                                        classes=list(CLASS_NAMES), target_size=(IMAGE_SHAPE[0], IMAGE_SHAPE[1]),\n",
    "                                                        shuffle=True, subset=\"validation\")\n",
    "    return train_data_gen, test_data_gen, CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.api._v1.keras.layers' has no attribute 'experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ec689664342f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m data_augmentation = keras.Sequential(\n\u001b[0;32m      2\u001b[0m     [\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomFlip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"horizontal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomRotation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     ]\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\util\\module_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    191\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m       \u001b[0mattr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfmw_public_apis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v1.keras.layers' has no attribute 'experimental'"
     ]
    }
   ],
   "source": [
    "#data_augmentation = keras.Sequential(\n",
    "#    [\n",
    "#        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "#        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "#    ]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    # load MobileNetV2\n",
    "    \"\"\"model = MobileNetV2(input_shape=input_shape)\n",
    "    # remove the last fully connected layer\n",
    "    model.layers.pop()\n",
    "    # freeze all the weights of the model except the last 4 layers\n",
    "    for layer in model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    # construct our own fully connected layer for classification\n",
    "    output = Dense(num_classes, activation=\"softmax\")\n",
    "    # connect that dense layer to the model\n",
    "    output = output(model.layers[-1].output)\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    # print the summary of the model architecture\n",
    "    model.summary()\n",
    "    # training the model using rmsprop optimizer\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\"\"\"\n",
    "    \n",
    "    base_model = Xception(\n",
    "        weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "    )  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    # Freeze the base_model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create new model on top\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    #x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "    x = inputs\n",
    "\n",
    "    # Pre-trained Xception weights requires that input be normalized\n",
    "    # from (0, 255) to a range (-1., +1.), the normalization layer\n",
    "    # does the following, outputs = (inputs - mean) / sqrt(var)\n",
    "    \n",
    "    #norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
    "    #mean = np.array([127.5] * 3)\n",
    "    #var = mean ** 2\n",
    "    ## Scale inputs to [-1, +1]\n",
    "    #x = norm_layer(x)\n",
    "    \n",
    "    #norm_layer.set_weights([mean, var])\n",
    "\n",
    "    # The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "    # when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "    # base_model is running in inference mode here.\n",
    "    x = base_model(x, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
    "    outputs = keras.layers.Dense(1)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        metrics=[keras.metrics.BinaryAccuracy()],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 2527\n",
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'output_masks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-64e9500b1b1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# constructs the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mIMAGE_SHAPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# model name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"MobileNetV2_finetune_last5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-67313106d02d>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# when we unfreeze the base model for fine-tuning, so we make sure that the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# base_model is running in inference mode here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Regularize with dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;31m# Handle mask propagation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0mprevious_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_collect_previous_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m             \u001b[0muser_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_all_none\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_collect_previous_mask\u001b[1;34m(input_tensors)\u001b[0m\n\u001b[0;32m   1439\u001b[0m             \u001b[0minbound_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m             \u001b[0mnode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minbound_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_masks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m             \u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Node' object has no attribute 'output_masks'"
     ]
    }
   ],
   "source": [
    "# load the data generators\n",
    "train_generator, validation_generator, class_names = load_data()\n",
    "# constructs the model\n",
    "model = create_model(input_shape=IMAGE_SHAPE)\n",
    "# model name\n",
    "model_name = \"MobileNetV2_finetune_last5\"\n",
    "# some nice callbacks\n",
    "tensorboard = TensorBoard(log_dir=f\"logs/{model_name}\")\n",
    "checkpoint = ModelCheckpoint(f\"results/{model_name}\" + \"-loss-{val_loss:.2f}-acc-{val_accuracy:.2f}.h5\",\n",
    "                            save_best_only=True,\n",
    "                            verbose=1)\n",
    "# make sure results folder exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "# count number of steps per epoch\n",
    "training_steps_per_epoch = np.ceil(train_generator.samples / batch_size)\n",
    "validation_steps_per_epoch = np.ceil(validation_generator.samples / batch_size)\n",
    "# train using the generators\n",
    "H = model.fit_generator(train_generator, steps_per_epoch=training_steps_per_epoch,\n",
    "                    validation_data=validation_generator, validation_steps=validation_steps_per_epoch,\n",
    "                    epochs=epochs, verbose=1, callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
