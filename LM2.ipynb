{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.7.7 (default, May  6 2020, 11:45:54) [MSC v.1916 64 bit (AMD64)]\n",
      "keras version 2.3.1\n",
      "tensorflow version 1.15.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import keras, sys, time, os, warnings, cv2\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "#config.gpu_options.visible_device_list = \"1\" \n",
    "set_session(tf.Session(config=config))   \n",
    "\n",
    "\n",
    "print(\"python {}\".format(sys.version))\n",
    "print(\"keras version {}\".format(keras.__version__)); del keras\n",
    "print(\"tensorflow version {}\".format(tf.__version__))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FTRAIN = \"/images/params.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height, input_width = 384, 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_k(x0,y0,sigma, width, height):\n",
    "        \"\"\" Make a square gaussian kernel centered at (x0, y0) with sigma as SD.\n",
    "        \"\"\"\n",
    "        x = np.arange(0, width, 1, float) ## (width,)\n",
    "        y = np.arange(0, height, 1, float)[:, np.newaxis] ## (height,1)\n",
    "        return np.exp(-((x-x0)**2 + (y-y0)**2) / (2*sigma**2))\n",
    "\n",
    "def generate_hm(height, width ,landmarks,s=3):\n",
    "        \"\"\" Generate a full Heap Map for every landmarks in an array\n",
    "        Args:\n",
    "            height    : The height of Heat Map (the height of target output)\n",
    "            width     : The width  of Heat Map (the width of target output)\n",
    "            joints    : [(x1,y1),(x2,y2)...] containing landmarks\n",
    "            maxlenght : Lenght of the Bounding Box\n",
    "        \"\"\"\n",
    "        Nlandmarks = len(landmarks)\n",
    "        hm = np.zeros((height, width, Nlandmarks), dtype = np.float32)\n",
    "        for i in range(Nlandmarks):\n",
    "            if not np.array_equal(landmarks[i], [-1,-1]):\n",
    "             \n",
    "                hm[:,:,i] = gaussian_k(landmarks[i][0],\n",
    "                                        landmarks[i][1],\n",
    "                                        s,height, width)\n",
    "            else:\n",
    "                hm[:,:,i] = np.zeros((height,width))\n",
    "        return hm\n",
    "    \n",
    "def get_y_as_heatmap(df,height,width, sigma):\n",
    "    \n",
    "    columns_lmxy = df.columns[:-1] ## the last column contains Image\n",
    "    columns_lm = [] \n",
    "    for c in columns_lmxy:\n",
    "        c = c[:-2]\n",
    "        if c not in columns_lm:\n",
    "            columns_lm.extend([c])\n",
    "    \n",
    "    y_train = []\n",
    "    for i in range(df.shape[0]):\n",
    "        landmarks = []\n",
    "        for colnm in columns_lm:\n",
    "            x = df[colnm + \"_x\"].iloc[i] * input_width\n",
    "            y = df[colnm + \"_y\"].iloc[i] * input_height\n",
    "            if np.isnan(x) or np.isnan(y):\n",
    "                x, y = -1, -1\n",
    "            landmarks.append([x,y])\n",
    "            \n",
    "        y_train.append(generate_hm(height, width, landmarks, sigma))\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    \n",
    "    return(y_train,df[columns_lmxy],columns_lmxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 384, 384, 1)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 384, 384, 64)      640       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 384, 384, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 192, 192, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 192, 192, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 192, 192, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 96, 96, 128)       0         \n",
      "_________________________________________________________________\n",
      "bottleneck_1 (Conv2D)        (None, 96, 96, 160)       188743840 \n",
      "_________________________________________________________________\n",
      "bottleneck_2 (Conv2D)        (None, 96, 96, 160)       25760     \n",
      "_________________________________________________________________\n",
      "upsample_2 (Conv2DTranspose) (None, 384, 384, 64)      163840    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 9437184, 1)        0         \n",
      "=================================================================\n",
      "Total params: 189,192,448\n",
      "Trainable params: 189,192,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## output shape is the same as input\n",
    "output_height, output_width = input_height, input_width \n",
    "n = 32*5\n",
    "nClasses = 64\n",
    "nfmp_block1 = 64\n",
    "nfmp_block2 = 128\n",
    "\n",
    "IMAGE_ORDERING =  \"channels_last\" \n",
    "img_input = Input(shape=(input_height,input_width, 1)) \n",
    "\n",
    "# Encoder Block 1\n",
    "x = Conv2D(nfmp_block1, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "x = Conv2D(nfmp_block1, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "block1 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    \n",
    "# Encoder Block 2\n",
    "x = Conv2D(nfmp_block2, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(block1)\n",
    "x = Conv2D(nfmp_block2, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    \n",
    "## bottoleneck    \n",
    "o = (Conv2D(n, (input_height//4, input_width//4), \n",
    "            activation='relu' , padding='same', name=\"bottleneck_1\", data_format=IMAGE_ORDERING))(x)\n",
    "o = (Conv2D(n , ( 1 , 1 ) , activation='relu' , padding='same', name=\"bottleneck_2\", data_format=IMAGE_ORDERING))(o)\n",
    "\n",
    "\n",
    "## upsamping to bring the feature map size to be the same as the one from block1\n",
    "## o_block1 = Conv2DTranspose(nfmp_block1, kernel_size=(2,2),  strides=(2,2), use_bias=False, name='upsample_1', data_format=IMAGE_ORDERING )(o)\n",
    "## o = Add()([o_block1,block1])\n",
    "## output   = Conv2DTranspose(nClasses,    kernel_size=(2,2),  strides=(2,2), use_bias=False, name='upsample_2', data_format=IMAGE_ORDERING )(o)\n",
    "\n",
    "## Decoder Block\n",
    "## upsampling to bring the feature map size to be the same as the input image i.e., heatmap size\n",
    "output   = Conv2DTranspose(nClasses,    kernel_size=(4,4),  strides=(4,4), use_bias=False, name='upsample_2', data_format=IMAGE_ORDERING )(o)\n",
    "\n",
    "## Reshaping is necessary to use sample_weight_mode=\"temporal\" which assumes 3 dimensional output shape\n",
    "## See below for the discussion of weights\n",
    "output = Reshape((output_width*input_height*nClasses,1))(output)\n",
    "model = Model(img_input, output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',optimizer=\"rmsprop\",sample_weight_mode=\"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(fname):\n",
    "    img = cv2.imread(fname, cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "    #if img is None:\n",
    "    #     return None\n",
    "    img = cv2.resize(img, (input_width, input_height))\n",
    "    #img = img[np.newaxis, :]\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeData(data):\n",
    "    return (data - np.min(data)) / float(np.max(data) - np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(width=input_width,height=input_height,sigma=5):\n",
    "    \"\"\"\n",
    "    load test/train data\n",
    "    cols : a list containing landmark label names.\n",
    "           If this is specified, only the subset of the landmark labels are \n",
    "           extracted. for example, cols could be:\n",
    "           \n",
    "          [left_eye_center_x, left_eye_center_y]\n",
    "            \n",
    "    return: \n",
    "    X:  2-d numpy array (Nsample, Ncol*Nrow)\n",
    "    y:  2-d numpy array (Nsample, Nlandmarks*2) \n",
    "        In total there are 15 landmarks. \n",
    "        As x and y coordinates are recorded, u.shape = (Nsample,30)\n",
    "    y0: panda dataframe containins the landmarks\n",
    "       \n",
    "    \"\"\"\n",
    "    from sklearn.utils import shuffle\n",
    "    \n",
    "    fname = FTRAIN\n",
    "    df = pd.read_csv(os.path.expanduser(fname)) \n",
    "\n",
    "    y, y0, nm_landmark = get_y_as_heatmap(df,height,width, sigma)\n",
    "    X, y, y0 = shuffle(X, y, y0, random_state=42)  # shuffle data   \n",
    "    y = y.astype(np.float32)\n",
    "    \n",
    "    \n",
    "    df['Image'] = df['id_string'].apply(lambda im: get_image('/images/all_images/' + im + '.tif'))\n",
    "\n",
    "\n",
    "    myprint = df.count()\n",
    "    myprint = myprint.reset_index()\n",
    "    print(myprint)  \n",
    "    ## row with at least one NA columns are removed!\n",
    "    ## df = df.dropna()  \n",
    "    df = df.fillna(-1)\n",
    "\n",
    "    #X = np.vstack(df['Image'].values) / 255.  # changes valeus between 0 and 1\n",
    "    X = NormalizeData(np.vstack(df['Image'].values))\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    \n",
    "    return X, y, y0, nm_landmark\n",
    "\n",
    "def load2d(width=input_width,height=input_height,sigma=5):\n",
    "\n",
    "    re   = load(width,height,sigma)\n",
    "    X    = re[0].reshape(-1,width,height,1)\n",
    "    y, y0, nm_landmarks = re[1:]\n",
    "    \n",
    "    return X, y, y0, nm_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 36.0 MiB for an array with shape (384, 384, 64) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-129f8bacf7bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnm_landmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-0ce4378039ce>\u001b[0m in \u001b[0;36mload2d\u001b[1;34m(width, height, sigma)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_width\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_height\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mre\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mX\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnm_landmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-0ce4378039ce>\u001b[0m in \u001b[0;36mload\u001b[1;34m(width, height, sigma)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnm_landmark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_y_as_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# shuffle data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-fb34fda08c5a>\u001b[0m in \u001b[0;36mget_y_as_heatmap\u001b[1;34m(df, height, width, sigma)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mlandmarks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_hm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-fb34fda08c5a>\u001b[0m in \u001b[0;36mgenerate_hm\u001b[1;34m(height, width, landmarks, s)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \"\"\"\n\u001b[0;32m     16\u001b[0m         \u001b[0mNlandmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mhm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNlandmarks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNlandmarks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlandmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 36.0 MiB for an array with shape (384, 384, 64) and data type float32"
     ]
    }
   ],
   "source": [
    "sigma = 5\n",
    "\n",
    "X_train, y_train, y_train0, nm_landmarks = load2d(sigma=sigma)\n",
    "print (X_train.shape,y_train.shape, y_train0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
